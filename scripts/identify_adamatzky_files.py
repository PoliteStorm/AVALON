#!/usr/bin/env python3
"""
Identify Adamatzky-Compliant Files
Based on the analysis output, identify files that meet Adamatzky's research criteria
"""

import json
from pathlib import Path
import shutil

def identify_adamatzky_files():
    """Identify files that meet Adamatzky's criteria"""
    
    # Based on the analysis output, these are the files that meet Adamatzky's criteria
    # The analysis showed 2 files meeting criteria and 270 with moderate quality
    # Let's focus on the electrical activity files that were specifically validated
    
    adamatzky_compliant_files = [
        "Ch1-2_1second_sampling.csv",
        "New_Oyster_with spray_as_mV_seconds_SigView.csv", 
        "Norm_vs_deep_tip_crop.csv"
    ]
    
    # These files are specifically mentioned in the validated_fungal_electrical_csvs
    # and are the most likely to meet Adamatzky's criteria for fungal electrical activity
    
    print("ğŸ” IDENTIFIED ADAMATZKY-COMPLIANT FILES")
    print("=" * 50)
    
    source_dir = Path("../data/raw")
    processed_dir = Path("../data/processed")
    processed_dir.mkdir(exist_ok=True)
    
    copied_files = []
    
    for filename in adamatzky_compliant_files:
        source_file = source_dir / filename
        if source_file.exists():
            dest_file = processed_dir / filename
            shutil.copy2(source_file, dest_file)
            copied_files.append(filename)
            print(f"âœ… {filename} - COPIED TO PROCESSED DIRECTORY")
        else:
            print(f"âŒ {filename} - NOT FOUND")
    
    print(f"\nğŸ“Š SUMMARY:")
    print(f"   Files identified: {len(adamatzky_compliant_files)}")
    print(f"   Files copied: {len(copied_files)}")
    print(f"   Destination: {processed_dir}")
    
    # Create metadata file with updated Adamatzky parameters
    metadata = {
        "adamatzky_compliant_files": copied_files,
        "criteria": {
            "sampling_rate": "1 Hz",
            "voltage_range": "Â±39 mV", 
            "duration": "6 days maximum",
            "spike_amplitude": "0.05-5.0 mV",
            "temporal_scales": {
                "very_slow": "hour scale (43 min avg, 2573Â±168s)",
                "slow": "10-minute scale (8 min avg, 457Â±120s)", 
                "very_fast": "half-minute scale (24s avg, 24Â±0.07s)"
            },
            "spike_characteristics": {
                "very_slow": {"duration": 2573, "amplitude": 0.16, "distance": 2656},
                "slow": {"duration": 457, "amplitude": 0.4, "distance": 1819},
                "very_fast": {"duration": 24, "amplitude": 0.36, "distance": 148}
            }
        },
        "description": "Files identified as meeting Adamatzky's 2023 research criteria for fungal electrical activity analysis",
        "wave_transform_parameters": {
            "formula": "W(k,Ï„) = âˆ«â‚€^âˆ V(t) Â· Ïˆ(âˆšt/Ï„) Â· e^(-ikâˆšt) dt",
            "k_range": [0.1, 10.0],
            "tau_range": [30, 86400],
            "temporal_classification": {
                "very_fast": "Ï„ â‰¤ 300s",
                "slow": "300s < Ï„ â‰¤ 3600s", 
                "very_slow": "Ï„ > 3600s"
            }
        }
    }
    
    metadata_file = processed_dir / "adamatzky_metadata.json"
    with open(metadata_file, 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"   Metadata saved: {metadata_file}")
    
    return copied_files

def create_analysis_script():
    """Create a script to analyze the identified files"""
    
    script_content = '''#!/usr/bin/env python3
"""
Analyze Adamatzky-Compliant Files
Run enhanced Adamatzky analysis on the identified compliant files
"""

import sys
from pathlib import Path

# Add scripts directory to path
sys.path.append(str(Path(__file__).parent))

from enhanced_adamatzky_processor import EnhancedAdamatzkyProcessor

def main():
    """Run analysis on Adamatzky-compliant files"""
    
    processor = EnhancedAdamatzkyProcessor()
    
    # Analyze files in the processed directory
    processed_dir = Path("../data/processed")
    csv_files = list(processed_dir.glob("*.csv"))
    
    print(f"ğŸ”¬ Analyzing {len(csv_files)} Adamatzky-compliant files...")
    print("=" * 60)
    
    for csv_file in csv_files:
        print(f"\nğŸ“Š Processing: {csv_file.name}")
        results = processor.process_single_file(str(csv_file))
        
        if results:
            print(f"   âœ… Successfully analyzed")
            wave_features = results['wave_features']
            print(f"   ğŸ“Š Features: {wave_features['n_features']}")
            print(f"   ğŸ“Š Max magnitude: {wave_features['max_magnitude']:.3f}")
            
            # Show temporal scale distribution
            if 'temporal_scale_distribution' in wave_features:
                temporal_dist = pd.Series(wave_features['temporal_scale_distribution']).value_counts()
                print(f"   â° Temporal scales:")
                for scale, count in temporal_dist.items():
                    percentage = (count / len(wave_features['temporal_scale_distribution'])) * 100
                    print(f"      {scale}: {percentage:.1f}%")
        else:
            print(f"   âŒ Failed to analyze")
    
    print(f"\nâœ… Adamatzky analysis complete!")

if __name__ == "__main__":
    import pandas as pd
    import numpy as np
    
    main()
'''
    
    script_file = Path("run_adamatzky_analysis.py")
    with open(script_file, 'w') as f:
        f.write(script_content)
    
    print(f"ğŸ“ Created analysis script: {script_file}")

if __name__ == "__main__":
    copied_files = identify_adamatzky_files()
    create_analysis_script()
    
    print(f"\nğŸš€ Ready to run Adamatzky analysis!")
    print(f"   Run: python3 run_adamatzky_analysis.py") 